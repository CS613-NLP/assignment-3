# assignment-3
This repository contains the python scripts and notebooks for Assignment-3 NLP.

The assignment is divided into 3 main sections:
- Pretraining the model(bert-base-uncased) on given dataset (wikitext_raw_2_v1)
- Finetuning the pretrained model for specific tasks (Classification and Question & Answering)
- Evaluation of finetuned models using specified metrics (Classification: Accuracy, Precision, Recall, F1 ; Question-Answering: squad_v2, F1, METEOR, BLEU, ROUGE, exact-match)

To find all the respective code files, refer to the below file structure:

- Pre-training Dataset: [wikitext_raw_2_v1](wikitext_raw_2_v1.txt)
- Pre-training Dataset Eval: [wikitext_raw_2_v1_test](wikitext_raw_2_v1_test.txt)


Our pre-trained model is pushed on Hugging Face as: Skratch99/bert-pretrained
Our fine-tuned model for classification is pushed as: 
Our fine-tuned model for question & answering is pushed as: 

The assignment report can be found here.
